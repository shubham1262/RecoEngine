{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from copy import deepcopy\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import implicit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating       time\n",
       "0        1         1       5  874965758\n",
       "1        1         2       3  876893171\n",
       "2        1         3       4  878542960\n",
       "3        1         4       3  876893119\n",
       "4        1         5       3  889751712"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['user_id', 'movie_id', 'rating', 'time']\n",
    "df_train = pd.read_csv('ml-100k/u1.base', delimiter='\\t', header=None, names=colnames)\n",
    "df_test = pd.read_csv('ml-100k/u1.test', delimiter='\\t', header=None, names=colnames)\n",
    "df_full = pd.concat([df_train, df_test])\n",
    "df_full.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_rating(data):\n",
    "    temp = data.copy()\n",
    "    temp['rating']=np.where(temp['rating']>0,1,0)\n",
    "    return temp\n",
    "\n",
    "def sample_negative(data,item_list):\n",
    "    interact_status=data.groupby('user_id')['movie_id'].apply(set).reset_index().rename(columns={'movie_id':'interacted_items'})\n",
    "    interact_status['negative_items']=interact_status['interacted_items'].apply(lambda x: item_pool-x)\n",
    "    interact_status['negative_sample']=interact_status['negative_items'].apply(lambda x: random.sample(list(x),99)) #Sample negative examples\n",
    "    #interact_status['negative_sample']=interact_status['negative_sample'].apply(set)\n",
    "    return interact_status[['user_id', 'negative_items', 'negative_sample']]\n",
    "\n",
    "def split_loo(ratings):\n",
    "    \"\"\"train/test split using leave one out strategy\"\"\"\n",
    "\n",
    "    ratings['rank_latest'] = ratings.groupby(['user_id'])['time'].rank(\n",
    "        method='first', ascending=False)\n",
    "    \n",
    "    test = ratings[ratings['rank_latest'] == 1]\n",
    "    train = ratings[ratings['rank_latest'] > 1]\n",
    "\n",
    "    assert train['user_id'].nunique() == test['user_id'].nunique()\n",
    "    return train[['user_id', 'movie_id', 'rating']], test[['user_id', 'movie_id', 'rating']]\n",
    "\n",
    "class UserItemRatingDataset(Dataset):\n",
    "    \"\"\"Wrapper, convert <user, item, rating> Tensor into Pytorch Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, user_tensor, item_tensor, target_tensor):\n",
    "        self.user_tensor = user_tensor\n",
    "        self.item_tensor = item_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.user_tensor[index], self.item_tensor[index], self.target_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.user_tensor.size(0)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "### utils\n",
    "def resume_checkpoint(model, model_dir, device_id):\n",
    "    state_dict = torch.load(\n",
    "        model_dir,\n",
    "        map_location=lambda storage, loc: storage.cuda(device=device_id)\n",
    "        ) \n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>458</td>\n",
       "      <td>648</td>\n",
       "      <td>1</td>\n",
       "      <td>886395899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>458</td>\n",
       "      <td>1101</td>\n",
       "      <td>1</td>\n",
       "      <td>886397931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>459</td>\n",
       "      <td>934</td>\n",
       "      <td>1</td>\n",
       "      <td>879563639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>460</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>882912371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>462</td>\n",
       "      <td>682</td>\n",
       "      <td>1</td>\n",
       "      <td>886365231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating       time\n",
       "0            1         1       1  874965758\n",
       "1            1         2       1  876893171\n",
       "2            1         3       1  878542960\n",
       "3            1         4       1  876893119\n",
       "4            1         5       1  889751712\n",
       "...        ...       ...     ...        ...\n",
       "19995      458       648       1  886395899\n",
       "19996      458      1101       1  886397931\n",
       "19997      459       934       1  879563639\n",
       "19998      460        10       1  882912371\n",
       "19999      462       682       1  886365231\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_process=binary_rating(df_full)\n",
    "df_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pool = set(df_process['user_id'].unique())\n",
    "item_pool = set(df_process['movie_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>negative_items</th>\n",
       "      <th>negative_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{273, 274, 275, 276, 277, 278, 279, 280, 281, ...</td>\n",
       "      <td>[704, 460, 1463, 942, 847, 930, 1544, 680, 157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 1...</td>\n",
       "      <td>[130, 1042, 1015, 233, 112, 1023, 1526, 1074, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[1527, 1098, 129, 1099, 1424, 474, 1116, 930, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15...</td>\n",
       "      <td>[1042, 624, 1158, 1405, 1570, 1668, 291, 69, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>{3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[1549, 331, 1600, 1632, 1420, 1261, 1268, 983,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>939</td>\n",
       "      <td>{1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[1125, 915, 604, 277, 674, 1559, 1398, 761, 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>940</td>\n",
       "      <td>{1, 2, 3, 5, 6, 10, 11, 13, 15, 16, 17, 18, 19...</td>\n",
       "      <td>[492, 1396, 1162, 1500, 569, 1523, 268, 1064, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>941</td>\n",
       "      <td>{2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, ...</td>\n",
       "      <td>[1378, 185, 525, 1436, 1169, 1580, 553, 1281, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[802, 549, 369, 1211, 1084, 147, 138, 1145, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>943</td>\n",
       "      <td>{1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 17, ...</td>\n",
       "      <td>[826, 297, 45, 956, 1123, 1033, 1326, 1428, 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                     negative_items  \\\n",
       "0          1  {273, 274, 275, 276, 277, 278, 279, 280, 281, ...   \n",
       "1          2  {2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 1...   \n",
       "2          3  {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "3          4  {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15...   \n",
       "4          5  {3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "..       ...                                                ...   \n",
       "938      939  {1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 1...   \n",
       "939      940  {1, 2, 3, 5, 6, 10, 11, 13, 15, 16, 17, 18, 19...   \n",
       "940      941  {2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, ...   \n",
       "941      942  {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "942      943  {1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 17, ...   \n",
       "\n",
       "                                       negative_sample  \n",
       "0    [704, 460, 1463, 942, 847, 930, 1544, 680, 157...  \n",
       "1    [130, 1042, 1015, 233, 112, 1023, 1526, 1074, ...  \n",
       "2    [1527, 1098, 129, 1099, 1424, 474, 1116, 930, ...  \n",
       "3    [1042, 624, 1158, 1405, 1570, 1668, 291, 69, 7...  \n",
       "4    [1549, 331, 1600, 1632, 1420, 1261, 1268, 983,...  \n",
       "..                                                 ...  \n",
       "938  [1125, 915, 604, 277, 674, 1559, 1398, 761, 75...  \n",
       "939  [492, 1396, 1162, 1500, 569, 1523, 268, 1064, ...  \n",
       "940  [1378, 185, 525, 1436, 1169, 1580, 553, 1281, ...  \n",
       "941  [802, 549, 369, 1211, 1084, 147, 138, 1145, 10...  \n",
       "942  [826, 297, 45, 956, 1123, 1033, 1326, 1428, 14...  \n",
       "\n",
       "[943 rows x 3 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_negative=sample_negative(df_process,item_pool)\n",
    "df_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_loo(df_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add negative data for implicit data (no rating data)\n",
    "num_neg = 2\n",
    "df_train = pd.merge(df_train, df_negative[['user_id', 'negative_items']], on='user_id')\n",
    "df_train['negatives'] = df_train['negative_items'].apply(lambda x: random.sample(list(x), num_neg))\n",
    "df_test = pd.merge(df_test, df_negative[['user_id', 'negative_items']], on='user_id')\n",
    "df_test['negatives'] = df_test['negative_items'].apply(lambda x: random.sample(list(x), num_neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users_train = df_train['user_id'].values.tolist()\n",
    "items_train = df_train['movie_id'].values.tolist()\n",
    "ratings_train = df_train['rating'].astype(float).values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Item, Users, Rating to the pool of + ves examples\n",
    "for i in range(num_neg):\n",
    "    users_train += df_train['user_id'].values.tolist()\n",
    "    items_train += df_train['negatives'].apply(lambda x: x[i]).values.tolist()\n",
    "    ratings_train += [0]*len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UserItemRatingDataset(\n",
    "    user_tensor=torch.LongTensor(users_train),\n",
    "    item_tensor=torch.LongTensor(items_train),\n",
    "    target_tensor=torch.FloatTensor(ratings_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sample, item_sample, target_sample = next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMF (Generalized Matrix Factorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Size: torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "gmf_config = {\n",
    "    'alias': 'gmf_factor8neg2-implict',\n",
    "    'num_epoch': 20,\n",
    "    'batch_size': 256,\n",
    "    'optimizer': 'adam',\n",
    "    'adam_lr': 1e-3,\n",
    "    'num_users': len(user_pool) + 1,\n",
    "    'num_items': len(item_pool) + 1,\n",
    "    'latent_dim': 8,\n",
    "    'num_negative': num_neg,\n",
    "    'l2_regularization': 0.01,\n",
    "    'use_cuda': True,\n",
    "    'device_id': 0,\n",
    "    'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'\n",
    "}\n",
    "\n",
    "class GMF(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GMF, self).__init__()\n",
    "        self.num_users = config['num_users']\n",
    "        self.num_items = config['num_items']\n",
    "        self.latent_dim = config['latent_dim']\n",
    "\n",
    "        self.embedding_user = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.latent_dim)\n",
    "        \n",
    "        self.embedding_item = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.latent_dim)\n",
    "\n",
    "        self.affine_output = torch.nn.Linear(\n",
    "            in_features=self.latent_dim, out_features=1)\n",
    "        \n",
    "        self.logistic = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "\n",
    "        # (m, latent_dim)\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        element_product = torch.mul(user_embedding, item_embedding) # Element wise product\n",
    "\n",
    "        # (m, 1)\n",
    "        logits = self.affine_output(element_product)\n",
    "        rating = self.logistic(logits)\n",
    "        return rating\n",
    "\n",
    "    def init_weight(self):\n",
    "        pass\n",
    "\n",
    "### testing\n",
    "gmf_model = GMF(gmf_config)\n",
    "result = gmf_model(user_sample, item_sample)\n",
    "print(f\"Result Size: {result.size()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Layer\n",
    "- https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Size: torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "# fit trained gmf layer into MLP\n",
    "\n",
    "mlp_config = {\n",
    "    'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\n",
    "    'num_epoch': 20,\n",
    "    'batch_size': 256,\n",
    "    'optimizer': 'adam',\n",
    "    'adam_lr': 1e-3,\n",
    "    'num_users': len(user_pool) + 1,\n",
    "    'num_items': len(item_pool) + 1,\n",
    "    'latent_dim': 8,\n",
    "    'num_negative': 2,\n",
    "    'layers': [16, 64, 32, 16, 8],  # layers[0] is the concat of latent user & latent item\n",
    "    'l2_regularization': 0.0000001,  # MLP model is sensitive to hyper params\n",
    "    'use_cuda': False,\n",
    "    'device_id': 7,\n",
    "    'pretrain': False,\n",
    "    'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model',\n",
    "    'pretrain_mf': True,\n",
    "    'pretrain_mf_loc': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "    }\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, config, gmf_model=None):\n",
    "\n",
    "        super(MLP, self).__init__()\n",
    "        self.config = config\n",
    "        self.num_users = config['num_users']\n",
    "        self.num_items = config['num_items']\n",
    "        self.latent_dim = config['latent_dim']\n",
    "\n",
    "        self.embedding_user = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.latent_dim)\n",
    "        \n",
    "        self.embedding_item = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.latent_dim)\n",
    "\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(config['layers'][:-1], config['layers'][1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.affine_output = torch.nn.Linear(in_features=config['layers'][-1], out_features=1)\n",
    "        self.logistic = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "\n",
    "        # (m, latent_dim)\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "\n",
    "        # the concat latent vector, (m, latent_dim * 2)\n",
    "        vector = torch.cat([user_embedding, item_embedding], dim=-1)  # Concatenation of vectors\n",
    "\n",
    "        # (m, latent_dim * 2) --> (m, 64, 32, ..., 8)\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            vector = self.fc_layers[idx](vector)\n",
    "            vector = torch.nn.ReLU()(vector)\n",
    "            # vector = torch.nn.BatchNorm1d()(vector)\n",
    "            # vector = torch.nn.Dropout(p=0.5)(vector)\n",
    "\n",
    "        # (m, 1)\n",
    "        logits = self.affine_output(vector)\n",
    "        rating = self.logistic(logits)\n",
    "        return rating\n",
    "\n",
    "    def init_weight(self):\n",
    "        pass\n",
    "\n",
    "### testing\n",
    "mlp_model = MLP(mlp_config, gmf_model)\n",
    "result = mlp_model(user_sample, item_sample)\n",
    "print(f\"Result Size: {result.size()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining MLP and GMF = NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Size: torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "neumf_config = {\n",
    "    'alias': 'pretrain_neumf_factor8neg4',\n",
    "    'num_epoch': 200,\n",
    "    'batch_size': 256,\n",
    "    'optimizer': 'adam',\n",
    "    'adam_lr': 1e-3,\n",
    "    'num_users': len(user_pool) + 1,\n",
    "    'num_items': len(item_pool) + 1,\n",
    "    'latent_dim_mf': 8,\n",
    "    'latent_dim_mlp': 8,\n",
    "    'num_negative': 2,\n",
    "    'layers': [16, 64, 32, 16, 8,120,200,130],\n",
    "    'l2_regularization': 0.01,\n",
    "    'use_cuda': False,\n",
    "    'device_id': 7,\n",
    "    'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model',\n",
    "    'pretrain': True,\n",
    "    'pretrain_mf_loc': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "    'pretrain_mlp_loc': 'checkpoints/{}'.format('mlp_factor8neg4_Epoch100_HR0.5606_NDCG0.2463.model'),\n",
    "    }\n",
    "\n",
    "class NeuMF(torch.nn.Module):\n",
    "    def __init__(self, config, gmf_model=None, mlp_model=None):\n",
    "\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.config = config\n",
    "        self.num_users = config['num_users']\n",
    "        self.num_items = config['num_items']\n",
    "        self.latent_dim_mf = config['latent_dim_mf']\n",
    "        self.latent_dim_mlp = config['latent_dim_mlp']\n",
    "\n",
    "        self.embedding_user_mlp = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.latent_dim_mlp)\n",
    "        \n",
    "        self.embedding_item_mlp = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.latent_dim_mlp)\n",
    "        \n",
    "        self.embedding_user_mf = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.latent_dim_mf)\n",
    "        \n",
    "        self.embedding_item_mf = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.latent_dim_mf)\n",
    "        \n",
    "        self.fc_layers = torch.nn.ModuleList() # Same as python list, but for pytorch\n",
    "        for idx, (in_size, out_size) in enumerate(zip(config['layers'][:-1], config['layers'][1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.affine_output = torch.nn.Linear(\n",
    "            in_features=config['layers'][-1] + config['latent_dim_mf'], out_features=1)\n",
    "        self.logistic = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "\n",
    "        # (m, latent_dim_mlp)\n",
    "        user_embedding_mlp = self.embedding_user_mlp(user_indices)\n",
    "        item_embedding_mlp = self.embedding_item_mlp(item_indices)\n",
    "\n",
    "        # (m, latent_dim_mf)\n",
    "        user_embedding_mf = self.embedding_user_mf(user_indices)\n",
    "        item_embedding_mf = self.embedding_item_mf(item_indices)\n",
    "\n",
    "        # (m, latent_dim_mlp * 2)\n",
    "        mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)\n",
    "\n",
    "        # (m, latent_dim_mf)\n",
    "        mf_vector = torch.mul(user_embedding_mf, item_embedding_mf)\n",
    "\n",
    "        # (m, latent_dim_mlp * 2) --> (m, 64) --> (m, latent_dim_mlp)\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            mlp_vector = self.fc_layers[idx](mlp_vector)\n",
    "            mlp_vector = torch.nn.ReLU()(mlp_vector)\n",
    "\n",
    "        # (m, enumerate + latent_dim_mf)\n",
    "        vector = torch.cat([mlp_vector, mf_vector], dim=-1)\n",
    "\n",
    "        # (m, 1)\n",
    "        logits = self.affine_output(vector)\n",
    "        rating = self.logistic(logits)\n",
    "        return rating\n",
    "\n",
    "    def init_weight(self):\n",
    "        pass\n",
    "\n",
    "### testing\n",
    "neumf_model = NeuMF(neumf_config, gmf_model, mlp_model)\n",
    "pred = neumf_model(user_sample, item_sample)\n",
    "print(f\"Result Size: {pred.size()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6863, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "### loss function\n",
    "criterion = torch.nn.BCELoss()\n",
    "loss = criterion(pred.view(-1), target_sample)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id movie_id  rating\n",
       "0        3      166       0\n",
       "0        3     1356       0\n",
       "1        4      990       0\n",
       "1        4     1031       0\n",
       "2        5     1408       0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for evaluation, give 1 positive sample and N negative sample to each user\n",
    "# the model will rank the N + 1 items\n",
    "\n",
    "g_truth = dict(zip(df_test['user_id'], df_test['movie_id']))\n",
    "d1 = df_test[['user_id', 'negatives']].copy()\n",
    "d1 = d1.explode('negatives')\n",
    "d1['rating'] = 0\n",
    "d1.rename(columns={'negatives' : 'movie_id'}, inplace=True)\n",
    "df_eval = pd.concat([d1, df_test[['user_id', 'movie_id', 'rating']]])\n",
    "df_eval.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Evaluation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "      <th>g_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>1</td>\n",
       "      <td>1014</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.498887</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>1</td>\n",
       "      <td>1202</td>\n",
       "      <td>0</td>\n",
       "      <td>0.486119</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>2</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>0.498252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>2</td>\n",
       "      <td>552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497930</td>\n",
       "      <td>2.0</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id movie_id  rating     score  rank  g_truth\n",
       "815        1     1014       0  0.510884   1.0       74\n",
       "815        1       74       1  0.498887   2.0       74\n",
       "815        1     1202       0  0.486119   3.0       74\n",
       "816        2      281       1  0.498252   1.0      281\n",
       "816        2      552       0  0.497930   2.0      281"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### rank according to score\n",
    "pred = neumf_model(\n",
    "    torch.LongTensor(df_eval['user_id'].values.tolist()), \n",
    "    torch.LongTensor(df_eval['movie_id'].values.tolist())\n",
    "    )\n",
    "df_eval['score'] = pred.view(-1).detach().numpy()\n",
    "df_eval['rank'] = df_eval.groupby('user_id')['score'].rank(method='first', ascending=False)\n",
    "df_eval.sort_values(['user_id', 'rank'], inplace=True)\n",
    "df_eval['g_truth'] = df_eval['user_id'].map(g_truth)\n",
    "df_eval.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR Ratio 0.6606574761399788\n",
      "NDCG 0.53502486839495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mr/_5z88nsx3jzgcnght0vscfv40000gp/T/ipykernel_40585/327308552.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_in_top_k['ndcg'] = test_in_top_k['rank'].apply(\n"
     ]
    }
   ],
   "source": [
    "# hit ratio\n",
    "def cal_hit_ratio(df, top_k=2):\n",
    "    \"\"\"Hit Ratio @ top_K\"\"\"\n",
    "\n",
    "    top_k = df[df['rank'] <= top_k].copy()\n",
    "    # golden items hit in the top_K items\n",
    "    test_in_top_k = top_k[top_k['movie_id'] == top_k['g_truth']]  \n",
    "    return len(test_in_top_k) * 1.0 / df['user_id'].nunique()\n",
    "\n",
    "hr_ratio = cal_hit_ratio(df_eval)\n",
    "print('HR Ratio', hr_ratio)\n",
    "\n",
    "# ndcg\n",
    "def cal_ndcg(df, top_k=2):\n",
    "    top_k = df[df['rank'] <= top_k].copy()\n",
    "    test_in_top_k = top_k[top_k['movie_id'] == top_k['g_truth']]  \n",
    "\n",
    "    # the rank starts from 1\n",
    "    # if rank is 1, then ndcg = 1\n",
    "    test_in_top_k['ndcg'] = test_in_top_k['rank'].apply(\n",
    "        lambda x: math.log(2) / math.log(1 + x)\n",
    "        )\n",
    "    return test_in_top_k['ndcg'].sum() * 1.0 / df['user_id'].nunique()\n",
    "\n",
    "ndcg = cal_ndcg(df_eval)\n",
    "print('NDCG', ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
